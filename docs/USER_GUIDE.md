# Shammah User Guide

**Version:** 0.4.0
**Last Updated:** 2026-02-12

## Table of Contents

1. [What is Shammah?](#what-is-shammah)
2. [Quick Start](#quick-start)
3. [Installation](#installation)
4. [First-Time Setup](#first-time-setup)
5. [Basic Usage](#basic-usage)
6. [Tool Confirmations](#tool-confirmations)
7. [Advanced Features](#advanced-features)
8. [Daemon Mode](#daemon-mode)
9. [Configuration](#configuration)
10. [Troubleshooting](#troubleshooting)

---

## What is Shammah?

Shammah is a **local-first AI coding assistant** that combines the power of:
- **Pre-trained local models** (Qwen via ONNX Runtime) - works offline, preserves privacy
- **Teacher APIs** (Claude, GPT-4, Gemini, Grok) - high-quality fallback when needed
- **Tool execution** - can read files, run commands, search code
- **Continuous learning** - adapts to your coding style via LoRA fine-tuning

### Key Benefits

‚úÖ **Works offline** - Local model runs on your machine
‚úÖ **Privacy-first** - Code stays on your device
‚úÖ **Instant startup** - <100ms to REPL (progressive loading)
‚úÖ **Adaptive** - Learns from your feedback
‚úÖ **Multi-provider** - Configure multiple teacher APIs
‚úÖ **Tool-enabled** - Can execute commands with your approval

---

## Quick Start

```bash
# Start interactive session
shammah

# Ask a question
> How do I use lifetimes in Rust?

# Let it use tools (with your approval)
> Can you read my Cargo.toml and suggest improvements?
```

That's it! Shammah will guide you through setup on first run.

---

## Installation

### From Source

```bash
# Clone repository
git clone https://github.com/schancel/shammah.git
cd shammah

# Build (requires Rust 1.70+)
cargo build --release

# Install
cargo install --path .

# Verify
shammah --version
```

### System Requirements

- **RAM:** 8GB minimum (16GB+ recommended)
- **Disk:** 5-10GB for models
- **OS:** macOS (Apple Silicon recommended), Linux, Windows
- **Rust:** 1.70 or newer

---

## First-Time Setup

When you run `shammah` for the first time, the setup wizard will guide you through:

### 1. Welcome Screen

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Welcome to Shammah Setup                    ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ This wizard will help you configure:       ‚îÇ
‚îÇ  ‚Ä¢ Teacher API (Claude/GPT-4/Gemini/Grok)  ‚îÇ
‚îÇ  ‚Ä¢ Local model (optional, offline mode)    ‚îÇ
‚îÇ  ‚Ä¢ Tool permissions                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Teacher API Configuration

**Recommended:** Start with Claude API for best results.

```
Teacher API Key:
> sk-ant-...

Which teachers would you like to configure?
  [x] Claude (Anthropic)  ‚Üê Selected
  [ ] GPT-4 (OpenAI)
  [ ] Gemini (Google)
  [ ] Grok (xAI)

Press 'a' to add more providers later.
```

You can add multiple providers and Shammah will use them as fallbacks.

### 3. Local Model Setup (Optional)

```
Would you like to enable local model?
  [x] Yes - Download model for offline use
  [ ] No - Use teacher APIs only

Model size (based on your RAM):
  [ ] Small (1.5B) - 8GB RAM
  [x] Medium (3B) - 16GB RAM  ‚Üê Recommended for 16GB systems
  [ ] Large (7B) - 32GB RAM
  [ ] XLarge (14B) - 64GB+ RAM
```

**First run:** Model downloads in background (5-30 minutes depending on size).
**Subsequent runs:** Instant startup, model loads from cache.

### 4. Completion

Setup is saved to `~/.shammah/config.toml`. You can edit it manually or re-run setup:

```bash
shammah setup
```

---

## Basic Usage

### Interactive REPL

```bash
shammah
```

This starts an interactive session. You can:
- Ask coding questions
- Request code reviews
- Get explanations
- Debug issues

**Example:**

```
‚ùØ What's the difference between String and &str in Rust?

String is an owned, heap-allocated string that can grow and shrink.
&str is a borrowed string slice, typically a view into a String or
string literal. Use &str for function parameters when you don't need
ownership, and String when you need to own or modify the data.

Would you like to see examples?
```

### Single Query Mode

```bash
shammah query "Explain async/await in Rust"
```

Runs a single query and exits - useful for scripts.

### Keyboard Shortcuts

- **Enter:** Submit query
- **Shift+Enter:** New line (multi-line input)
- **Ctrl+C:** Cancel in-progress query
- **Ctrl+G:** Mark response as good (for training)
- **Ctrl+B:** Mark response as bad (for training)
- **Up/Down:** Navigate command history
- **Esc:** (In dialogs) Cancel

---

## Tool Confirmations

When Shammah needs to execute tools (read files, run commands), it will ask for your approval:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tool 'bash' requires approval            ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ Input:                                   ‚îÇ
‚îÇ {                                        ‚îÇ
‚îÇ   "command": "cargo test"                ‚îÇ
‚îÇ }                                        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ 1. Allow Once                            ‚îÇ
‚îÇ 2. Allow Exact (Session)                 ‚îÇ
‚îÇ 3. Allow Pattern (Session)               ‚îÇ
‚îÇ 4. Allow Exact (Persistent)              ‚îÇ
‚îÇ 5. Allow Pattern (Persistent)            ‚îÇ
‚îÇ 6. Deny                                  ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ ‚Üë/‚Üì: Navigate  Enter: Confirm  Esc: Deny‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Approval Options

1. **Allow Once** - Execute this time only
2. **Allow Exact (Session)** - Allow this exact command until restart
3. **Allow Pattern (Session)** - Allow similar commands until restart
4. **Allow Exact (Persistent)** - Always allow this exact command
5. **Allow Pattern (Persistent)** - Always allow similar commands
6. **Deny** - Don't execute

**Patterns** let you approve categories of commands:
- `cargo test` in any directory
- Any `git` command in `/home/user/projects`
- Reading any file in `/home/user/safe-dir`

### Structured Patterns

You can create patterns that match command components separately:

```
cmd:"cargo test"  args:"*"  dir:"/home/*/projects"
```

This allows:
- `cargo test` in any user's projects directory
- Any arguments (e.g., `--release`, `--bin foo`)

Managed via `shammah tools` command.

---

## Advanced Features

### Command History

Press **Up/Down** arrows to navigate through previous queries.

History is saved to `~/.shammah/history.txt` (last 1000 commands).

### Feedback System

Help Shammah learn from your preferences:

- **Ctrl+G** - Good response (saves as training example)
- **Ctrl+B** - Bad response (saves as high-priority training data)

Feedback is weighted:
- Good: 1x weight
- Bad: 10x weight (learns faster from mistakes)

Data saved to `~/.shammah/feedback.jsonl` for LoRA training.

### Status Bar

The status bar shows:
```
Model: qwen-3b | Tokens: 234‚Üí156 | Latency: 1.2s | Speed: 130 tok/s | Memory: 4.2GB / 16GB
```

- **Model:** Current model being used
- **Tokens:** Input‚ÜíOutput token counts
- **Latency:** Response time
- **Speed:** Tokens per second
- **Memory:** Process/System RAM usage

### Multi-Provider Setup

Add additional teacher providers after initial setup:

```bash
shammah setup
# Navigate to teacher configuration
# Press 'a' to add a new provider
```

Providers are tried in order, with automatic fallback on errors.

---

## Daemon Mode

For advanced users and integrations.

### Auto-Spawning Daemon

The daemon starts automatically when you use `shammah`. It:
- Runs in background
- Serves OpenAI-compatible HTTP API
- Manages sessions and model loading
- Handles tool execution pass-through

### Manual Daemon Management

```bash
# Check daemon status
shammah daemon-status

# Stop daemon
shammah daemon-stop

# Start daemon manually
shammah daemon-start
```

### HTTP API

The daemon serves an OpenAI-compatible API on `http://127.0.0.1:8000`:

```bash
curl -X POST http://127.0.0.1:8000/v1/messages \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen-3b",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

Use this to integrate Shammah with other tools (VSCode extensions, etc.).

---

## Configuration

Config file: `~/.shammah/config.toml`

### Example Configuration

```toml
# Teacher API configuration
[teachers]
[[teachers.list]]
provider = "claude"
api_key = "sk-ant-..."
model = "claude-sonnet-4-5"

[[teachers.list]]
provider = "openai"
api_key = "sk-..."
model = "gpt-4"

# Local model configuration
[backend]
model_family = "Qwen"
model_size = "Medium"
execution_provider = "CoreML"  # or "CPU"

# Daemon configuration
[daemon]
bind_address = "127.0.0.1:8000"
auto_spawn = true

# LoRA training configuration
[lora]
rank = 16
alpha = 32.0
auto_train = true
auto_train_threshold = 10
high_weight = 10.0
medium_weight = 3.0
normal_weight = 1.0

# Tool permissions
[tools]
default_rule = "ask"  # "allow", "ask", or "deny"
max_tool_turns = 5
```

### Storage Locations

- **Config:** `~/.shammah/config.toml`
- **Models:** `~/.cache/huggingface/hub/`
- **Adapters:** `~/.shammah/adapters/`
- **Feedback:** `~/.shammah/feedback.jsonl`
- **History:** `~/.shammah/history.txt`
- **Tool Patterns:** `~/.shammah/tool_patterns.json`
- **Daemon PID:** `~/.shammah/daemon.pid`

---

## Troubleshooting

### Model Download Issues

**Problem:** Model download stuck or slow

```bash
# Check HuggingFace Hub cache
ls ~/.cache/huggingface/hub/

# Re-download model
rm -rf ~/.cache/huggingface/hub/models--*Qwen*
shammah  # Will re-download on startup
```

**Problem:** Not enough disk space

Local models require:
- 1.5B: ~3GB
- 3B: ~6GB
- 7B: ~14GB
- 14B: ~28GB

Free up space or use teacher-only mode (no local model).

### Daemon Issues

**Problem:** Daemon won't start

```bash
# Check if port is in use
lsof -i :8000

# Force stop any existing daemon
shammah daemon-stop
rm ~/.shammah/daemon.pid

# Start fresh
shammah
```

**Problem:** Connection refused errors

```bash
# Check daemon status
shammah daemon-status

# Restart daemon
shammah daemon-stop
shammah daemon-start
```

### Memory Issues

**Problem:** System running out of RAM

1. Use a smaller model size in config
2. Close other memory-intensive applications
3. Check memory usage: `shammah memory`
4. Consider teacher-only mode (no local model)

### Performance Issues

**Problem:** Slow responses

- **Local model:** Normal on first query (model loading), faster on subsequent queries
- **Teacher API:** Check network connection
- **Check status bar** for actual response times

**Problem:** High CPU usage

This is normal during:
- Model loading (first query)
- Model inference (generating responses)
- LoRA training (background, after feedback)

### Tool Execution Issues

**Problem:** Tools not executing

1. Check tool permissions in config
2. Ensure you're approving tools when prompted
3. Check `~/.shammah/tool_patterns.json` for conflicting patterns

**Problem:** Confirmation dialogs not showing

Make sure terminal height is at least 15 lines:
```bash
# Check terminal size
echo $LINES $COLUMNS

# Resize terminal if needed
```

### Getting Help

```bash
# Show help
shammah --help

# Show tool status
shammah tools

# Show memory usage
shammah memory

# View logs
tail -f ~/.shammah/logs/shammah.log  # if enabled
```

**GitHub Issues:** https://github.com/schancel/shammah/issues

---

## Tips & Best Practices

### 1. Start with Teacher APIs

Use Claude or GPT-4 first while local model downloads. You'll get high-quality responses immediately.

### 2. Approve Tool Patterns

Instead of approving every `cargo test` individually, approve the pattern once:
```
cmd:"cargo test" args:"*" dir:"/home/user/*"
```

### 3. Use Feedback Wisely

- **Ctrl+G (Good):** When response is exactly what you wanted
- **Ctrl+B (Bad):** When response has wrong approach or strategy

This helps LoRA training adapt to your preferences.

### 4. Multi-Provider Fallback

Configure multiple providers for resilience:
1. Claude (primary)
2. GPT-4 (fallback)
3. Gemini (backup)

If one is down or rate-limited, Shammah automatically tries the next.

### 5. Monitor Memory

Keep an eye on the status bar. If memory usage is high:
- Consider smaller model
- Close other applications
- Restart daemon to free memory

### 6. Keyboard Shortcuts

Learn the shortcuts:
- **Shift+Enter** for multi-line input
- **Up/Down** for history
- **Ctrl+C** to cancel long queries
- **Ctrl+G/B** for feedback

### 7. Review Tool Patterns

Periodically review your approved patterns:
```bash
shammah tools
```

Remove overly permissive patterns for security.

---

## What's Next?

- **Explore tools:** Let Shammah read your code, run tests, search files
- **Provide feedback:** Help it learn your preferences
- **Configure multiple providers:** Set up fallback APIs
- **Experiment with LoRA:** Train custom adapters for your domain

**Happy coding!** üöÄ

For more details, see:
- **CLAUDE.md** - AI assistant context and architecture
- **ARCHITECTURE.md** - Technical implementation details
- **STATUS.md** - Current project status and roadmap
